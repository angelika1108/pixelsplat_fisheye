{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import shutil\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import yaml\n",
    "import re\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import torchvision.transforms as tf\n",
    "import io\n",
    "from einops import rearrange, repeat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = \"02\"\n",
    "first_frame = 0\n",
    "last_frame = 99\n",
    "nb_frames = last_frame - first_frame + 1\n",
    "target_im_folder = f\"test_images_cam{cam}_{first_frame}_{last_frame}\"\n",
    "h_new = 360\n",
    "w_new = 640\n",
    "h_resize = 800\n",
    "w_resize = 800\n",
    "\n",
    "source_folder = f\"/home/angelika/pixelsplat_fisheye/datasets/kitti360/2013_05_28_drive_0000_sync/image_{cam}/data_rgb\"\n",
    "target_folder = f\"/home/angelika/pixelsplat_fisheye/datasets/kitti360/{target_im_folder}\"\n",
    "\n",
    "if not os.path.exists(target_folder):\n",
    "    os.makedirs(target_folder)\n",
    "\n",
    "\n",
    "# Get the list of filenames in the source folder\n",
    "filenames = sorted(os.listdir(source_folder))\n",
    "available_frames = []\n",
    "\n",
    "# Iterate over the filenames and copy images to the destination folder\n",
    "for i, filename in enumerate(filenames):\n",
    "    if i < nb_frames:\n",
    "        available_frames.append(i)\n",
    "        source_path = os.path.join(source_folder, filename)\n",
    "        filename_dest = filename\n",
    "        destination_path = os.path.join(target_folder, filename_dest)\n",
    "        \n",
    "        shutil.copy2(source_path, destination_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 16)\n"
     ]
    }
   ],
   "source": [
    "# Copy camera poses\n",
    "pose_file = f\"/home/angelika/pixelsplat_fisheye/datasets/kitti360/2013_05_28_drive_0000_sync/all_cam{cam[1:]}_to_world.txt\"\n",
    "\n",
    "# Extract poses\n",
    "cam2world = []\n",
    "\n",
    "# Read cam2world matrices\n",
    "for line in open(pose_file, 'r').readlines():\n",
    "    value = list(map(float, line.strip().split(\" \")))\n",
    "    cam2world.append(np.array(value[1:]))\n",
    "\n",
    "cam2world = np.array(cam2world)\n",
    "cam2world = cam2world[first_frame:last_frame+1]\n",
    "print(cam2world.shape)\n",
    "# Save only the poses to a .txt file\n",
    "with open(f'{target_folder}/camera_poses.txt', 'w') as file:\n",
    "    for i, row in enumerate(cam2world):\n",
    "        # line = [filenames[available_frames[i]]] + [str(x) for x in row]\n",
    "        line = [str(available_frames[i])] + [str(x) for x in row]\n",
    "        line = ' '.join(line) + '\\n'\n",
    "        file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dict = {}\n",
    "\n",
    "image_dict['url'] = \"\"\n",
    "image_dict['key'] = f\"kitti360_cam{cam}_{first_frame}_{last_frame}\"\n",
    "\n",
    "timestamps = torch.as_tensor(available_frames)\n",
    "image_dict['timestamps'] = timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam2world12 = torch.tensor(cam2world[:, :12])\n",
    "two_zeros = torch.zeros((nb_frames, 2))\n",
    "intrinsics = torch.zeros((nb_frames, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the world2cam matrix from cam2world12\n",
    "# similary as in pixelsplat_data.ipynb.\n",
    "### Code in pixelsplat_data.ipynb:\n",
    "### w2c = repeat(torch.eye(4, dtype=torch.float32), \"h w -> b h w\", b=b).clone()   # shape: (256, 4, 4)\n",
    "### w2c[:, :3] = rearrange(poses[:, 6:], \"b (h w) -> b h w\", h=3, w=4)  # shape: (256, 3, 4)\n",
    "### extrinsics =  w2c.inverse()\n",
    "\n",
    "w2c12 = repeat(torch.eye(4, dtype=torch.float32), \"h w -> b h w\", b=nb_frames).clone()\n",
    "w2c12[:, :3] = rearrange(cam2world12, \"nb_frames (h w) -> nb_frames h w\", h=3, w=4)\n",
    "world2cam123 = w2c12.inverse()\n",
    "world2cam16 = world2cam123.reshape(nb_frames, 16)\n",
    "world2cam12 = world2cam16[:, :12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readYAMLFile(fileName):\n",
    "    '''make OpenCV YAML file compatible with python'''\n",
    "    ret = {}\n",
    "    skip_lines=1    # Skip the first line which says \"%YAML:1.0\". Or replace it with \"%YAML 1.0\"\n",
    "    with open(fileName) as fin:\n",
    "        for i in range(skip_lines):\n",
    "            fin.readline()\n",
    "        yamlFileOut = fin.read()\n",
    "        myRe = re.compile(r\":([^ ])\")   # Add space after \":\", if it doesn't exist. Python yaml requirement\n",
    "        yamlFileOut = myRe.sub(r': \\1', yamlFileOut)\n",
    "        ret = yaml.safe_load(yamlFileOut)\n",
    "    return ret\n",
    "\n",
    "intrinsics_file = f'/home/angelika/datasets/kitti_360/calibration/image_{cam}.yaml'\n",
    "intrinsics_dict = readYAMLFile(intrinsics_file)\n",
    "\n",
    "h_old = intrinsics_dict['image_height']\n",
    "w_old = intrinsics_dict['image_width']\n",
    "\n",
    "intrinsics[:, 0] = torch.tensor(intrinsics_dict['projection_parameters']['gamma1']).repeat(nb_frames) / w_old\n",
    "intrinsics[:, 1] = torch.tensor(intrinsics_dict['projection_parameters']['gamma2']).repeat(nb_frames) / h_old\n",
    "intrinsics[:, 2] = torch.tensor(intrinsics_dict['projection_parameters']['u0']).repeat(nb_frames) / w_old\n",
    "intrinsics[:, 3] = torch.tensor(intrinsics_dict['projection_parameters']['v0']).repeat(nb_frames) / h_old\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Camera parameters\n",
    "poses = torch.cat((intrinsics, two_zeros, world2cam12), dim=1)\n",
    "poses.shape\n",
    "\n",
    "image_dict['cameras'] = poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert images and save them to image_dict\n",
    "\n",
    "flattened_images = []\n",
    "\n",
    "for i, filename in enumerate(filenames):\n",
    "    if i < nb_frames:\n",
    "        source_path = os.path.join(source_folder, filename)\n",
    "        image = Image.open(source_path)\n",
    "        im_resize = image.resize((360, 360))\n",
    "        # im_crop = im_resize.crop((80, 220, 720, 580))\n",
    "        im = Image.new(im_resize.mode, (w_new, h_new), (0,0,0))\n",
    "        im.paste(im_resize, ((w_new-360)//2, (h_new-360)//2))\n",
    "        \n",
    "        # Convert image to bytes\n",
    "        byte_stream = BytesIO()\n",
    "        im.save(byte_stream, format='PNG')  # Choose appropriate format, e.g., JPEG, PNG, etc.\n",
    "        image_bytes = byte_stream.getvalue()\n",
    "        byte_stream.close()\n",
    "\n",
    "        # Convert bytes to tensor\n",
    "        frameTensor = torch.tensor(np.frombuffer(image_bytes, dtype=np.uint8))\n",
    "        \n",
    "        flattened_images.append(frameTensor)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test one image\n",
    "# byte_stream = BytesIO()\n",
    "# image.save(byte_stream, format='PNG')  # Choose appropriate format, e.g., JPEG, PNG, etc.\n",
    "# image_bytes = byte_stream.getvalue()\n",
    "# byte_stream.close()\n",
    "\n",
    "# frameTensor = torch.tensor(np.frombuffer(image_bytes, dtype=np.uint8))\n",
    "\n",
    "# Check if the image is loaded correctly\n",
    "# image2 = Image.open(BytesIO(frameTensor.numpy().tobytes()))\n",
    "# image2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the images\n",
    "image_dict['images'] = flattened_images\n",
    "\n",
    "# Save the image_dict to a .torch file\n",
    "data = [image_dict]\n",
    "\n",
    "image_dict_name = \"000000\"\n",
    "torch.save(data, f'{target_folder}/{image_dict_name}.torch')\n",
    "torch.save(data, f'/home/angelika/pixelsplat_fisheye/datasets/kitti360/test/{image_dict_name}.torch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'url': '',\n",
       " 'key': 'kitti360_cam02_0_99',\n",
       " 'timestamps': tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
       "         54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
       "         72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
       "         90, 91, 92, 93, 94, 95, 96, 97, 98, 99]),\n",
       " 'cameras': tensor([[ 9.5452e-01,  9.5413e-01,  5.1210e-01,  ..., -3.5252e-01,\n",
       "          -1.6788e-02,  5.2317e+02],\n",
       "         [ 9.5452e-01,  9.5413e-01,  5.1210e-01,  ..., -3.5252e-01,\n",
       "          -1.6788e-02,  5.2317e+02],\n",
       "         [ 9.5452e-01,  9.5413e-01,  5.1210e-01,  ..., -3.4686e-01,\n",
       "          -1.7591e-02,  5.0042e+02],\n",
       "         ...,\n",
       "         [ 9.5452e-01,  9.5413e-01,  5.1210e-01,  ...,  8.5273e-01,\n",
       "           2.7282e-02, -3.6253e+03],\n",
       "         [ 9.5452e-01,  9.5413e-01,  5.1210e-01,  ...,  8.6420e-01,\n",
       "           2.7060e-02, -3.6518e+03],\n",
       "         [ 9.5452e-01,  9.5413e-01,  5.1210e-01,  ...,  8.7524e-01,\n",
       "           2.6817e-02, -3.6765e+03]]),\n",
       " 'images': [tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8)]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fisheye_psplat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad6da4dfbd24789c621481ef99b6ca206c23abc5e438488209ed0f151c17c055"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
