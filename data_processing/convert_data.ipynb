{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import shutil\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import yaml\n",
    "import re\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import torchvision.transforms as tf\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = \"02\"\n",
    "first_frame = 0\n",
    "last_frame = 99\n",
    "nb_frames = last_frame - first_frame + 1\n",
    "target_im_folder = f\"test_images_{cam}_{first_frame}_{last_frame}\"\n",
    "\n",
    "source_folder = f\"/home/angelika/pixelsplat_fisheye/datasets/kitti360/2013_05_28_drive_0000_sync/image_{cam}/data_rgb\"\n",
    "target_folder = f\"/home/angelika/pixelsplat_fisheye/datasets/kitti360/{target_im_folder}\"\n",
    "\n",
    "if not os.path.exists(target_folder):\n",
    "    os.makedirs(target_folder)\n",
    "\n",
    "\n",
    "# Get the list of filenames in the source folder\n",
    "filenames = sorted(os.listdir(source_folder))\n",
    "available_frames = []\n",
    "\n",
    "# Iterate over the filenames and copy images to the destination folder\n",
    "for i, filename in enumerate(filenames):\n",
    "    if i < nb_frames:\n",
    "        available_frames.append(i)\n",
    "        source_path = os.path.join(source_folder, filename)\n",
    "        filename_dest = filename\n",
    "        destination_path = os.path.join(target_folder, filename_dest)\n",
    "        \n",
    "        # shutil.copy2(source_path, destination_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy camera poses\n",
    "pose_file = f\"/home/angelika/pixelsplat_fisheye/datasets/kitti360/2013_05_28_drive_0000_sync/all_cam{cam[1:]}_to_world.txt\"\n",
    "\n",
    "# Extract poses\n",
    "cam2world = []\n",
    "\n",
    "# Read cam2world matrices\n",
    "for line in open(pose_file, 'r').readlines():\n",
    "    value = list(map(float, line.strip().split(\" \")))\n",
    "    cam2world.append(np.array(value[1:]))\n",
    "\n",
    "cam2world = np.array(cam2world)\n",
    "cam2world = cam2world[first_frame:last_frame+1]\n",
    "\n",
    "# Save only the poses to a .txt file\n",
    "with open(f'{target_folder}/camera_poses.txt', 'w') as file:\n",
    "    for i, row in enumerate(cam2world):\n",
    "        # line = [filenames[available_frames[i]]] + [str(x) for x in row]\n",
    "        line = [str(available_frames[i])] + [str(x) for x in row]\n",
    "        line = ' '.join(line) + '\\n'\n",
    "        # file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dict = {}\n",
    "\n",
    "image_dict['url'] = \"\"\n",
    "image_dict['key'] = f\"kitti360_cam{cam}_{first_frame}_{last_frame}\"\n",
    "\n",
    "timestamps = torch.as_tensor(available_frames)\n",
    "image_dict['timestamps'] = timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam2world12 = torch.tensor(cam2world[:, :12])\n",
    "two_zeros = torch.zeros((nb_frames, 2))\n",
    "intrinsics = torch.zeros((nb_frames, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readYAMLFile(fileName):\n",
    "    '''make OpenCV YAML file compatible with python'''\n",
    "    ret = {}\n",
    "    skip_lines=1    # Skip the first line which says \"%YAML:1.0\". Or replace it with \"%YAML 1.0\"\n",
    "    with open(fileName) as fin:\n",
    "        for i in range(skip_lines):\n",
    "            fin.readline()\n",
    "        yamlFileOut = fin.read()\n",
    "        myRe = re.compile(r\":([^ ])\")   # Add space after \":\", if it doesn't exist. Python yaml requirement\n",
    "        yamlFileOut = myRe.sub(r': \\1', yamlFileOut)\n",
    "        ret = yaml.safe_load(yamlFileOut)\n",
    "    return ret\n",
    "\n",
    "intrinsics_file = f'/home/angelika/datasets/kitti_360/calibration/image_{cam}.yaml'\n",
    "intrinsics_dict = readYAMLFile(intrinsics_file)\n",
    "\n",
    "intrinsics[:, 0] = torch.tensor(intrinsics_dict['projection_parameters']['gamma1']).repeat(nb_frames)\n",
    "intrinsics[:, 1] = torch.tensor(intrinsics_dict['projection_parameters']['gamma2']).repeat(nb_frames)\n",
    "intrinsics[:, 2] = torch.tensor(intrinsics_dict['projection_parameters']['u0']).repeat(nb_frames)\n",
    "intrinsics[:, 3] = torch.tensor(intrinsics_dict['projection_parameters']['v0']).repeat(nb_frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Camera parameters\n",
    "poses = torch.cat((cam2world12, two_zeros, intrinsics), dim=1)\n",
    "poses.shape\n",
    "\n",
    "image_dict['cameras'] = poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert images and save them to image_dict\n",
    "\n",
    "flattened_images = []\n",
    "\n",
    "for i, filename in enumerate(filenames):\n",
    "    if i < nb_frames:\n",
    "        source_path = os.path.join(source_folder, filename)\n",
    "        image = Image.open(source_path)\n",
    "        \n",
    "        # Convert image to bytes\n",
    "        byte_stream = BytesIO()\n",
    "        image.save(byte_stream, format='PNG')  # Choose appropriate format, e.g., JPEG, PNG, etc.\n",
    "        image_bytes = byte_stream.getvalue()\n",
    "        byte_stream.close()\n",
    "\n",
    "        # Convert bytes to tensor\n",
    "        frameTensor = torch.tensor(np.frombuffer(image_bytes, dtype=np.uint8))\n",
    "        \n",
    "        flattened_images.append(frameTensor)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test one image\n",
    "# byte_stream = BytesIO()\n",
    "# image.save(byte_stream, format='PNG')  # Choose appropriate format, e.g., JPEG, PNG, etc.\n",
    "# image_bytes = byte_stream.getvalue()\n",
    "# byte_stream.close()\n",
    "\n",
    "# frameTensor = torch.tensor(np.frombuffer(image_bytes, dtype=np.uint8))\n",
    "\n",
    "# Check if the image is loaded correctly\n",
    "# image2 = Image.open(BytesIO(frameTensor.numpy().tobytes()))\n",
    "# image2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the images\n",
    "image_dict['images'] = flattened_images\n",
    "\n",
    "# Save the image_dict to a .torch file\n",
    "data = [image_dict]\n",
    "\n",
    "image_dict_name = \"000000\"\n",
    "torch.save(data, f'{target_folder}/{image_dict_name}.torch')\n",
    "torch.save(data, f'/home/angelika/pixelsplat_fisheye/datasets/kitti360/test/{image_dict_name}.torch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'url': '',\n",
       " 'key': 'kitti360_cam02_0_99',\n",
       " 'timestamps': tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
       "         54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
       "         72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
       "         90, 91, 92, 93, 94, 95, 96, 97, 98, 99]),\n",
       " 'cameras': tensor([[-3.5136e-01, -3.3125e-02,  9.3566e-01,  ...,  1.3358e+03,\n",
       "           7.1694e+02,  7.0576e+02],\n",
       "         [-3.5136e-01, -3.3125e-02,  9.3566e-01,  ...,  1.3358e+03,\n",
       "           7.1694e+02,  7.0576e+02],\n",
       "         [-3.4567e-01, -3.3660e-02,  9.3775e-01,  ...,  1.3358e+03,\n",
       "           7.1694e+02,  7.0576e+02],\n",
       "         ...,\n",
       "         [ 8.5305e-01,  1.4611e-02,  5.2163e-01,  ...,  1.3358e+03,\n",
       "           7.1694e+02,  7.0576e+02],\n",
       "         [ 8.6450e-01,  1.4823e-02,  5.0241e-01,  ...,  1.3358e+03,\n",
       "           7.1694e+02,  7.0576e+02],\n",
       "         [ 8.7552e-01,  1.5042e-02,  4.8294e-01,  ...,  1.3358e+03,\n",
       "           7.1694e+02,  7.0576e+02]], dtype=torch.float64),\n",
       " 'images': [tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8),\n",
       "  tensor([137,  80,  78,  ...,  66,  96, 130], dtype=torch.uint8)]}"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fisheye_psplat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
