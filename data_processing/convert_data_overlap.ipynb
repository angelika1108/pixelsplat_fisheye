{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import shutil\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import yaml\n",
    "import re\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import torchvision.transforms as tf\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of frames: 249\n"
     ]
    }
   ],
   "source": [
    "interval_size = 1\n",
    "cam = \"02\"\n",
    "first_frame = 0\n",
    "source_folder = f\"/home/angelika/pixelsplat_fisheye/datasets/kitti360/2013_05_28_drive_0000_sync/image_{cam}/data_rgb\"\n",
    "\n",
    "# Get the list of filenames in the source folder\n",
    "filenames = sorted(os.listdir(source_folder))\n",
    "last_frame = 249\n",
    "print(f\"Number of frames: {last_frame}\")\n",
    "available_frames = []\n",
    "nb_frames = last_frame - first_frame + 1\n",
    "target_im_folder = f\"test_images_cam{cam}_{first_frame}_{last_frame}_overlap_{interval_size}\"\n",
    "target_folder = f\"/home/angelika/pixelsplat_fisheye/datasets/kitti360/{target_im_folder}\"\n",
    "\n",
    "if not os.path.exists(target_folder):\n",
    "    os.makedirs(target_folder)\n",
    "\n",
    "# Iterate over the filenames and copy images to the destination folder\n",
    "for i, filename in enumerate(filenames):\n",
    "    if i < nb_frames and i%interval_size==0:\n",
    "        available_frames.append(i)\n",
    "        source_path = os.path.join(source_folder, filename)\n",
    "        filename_dest = filename\n",
    "        destination_path = os.path.join(target_folder, filename_dest)\n",
    "        #shutil.copy2(source_path, destination_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 16)\n"
     ]
    }
   ],
   "source": [
    "# Copy camera poses\n",
    "pose_file = f\"/home/angelika/pixelsplat_fisheye/datasets/kitti360/2013_05_28_drive_0000_sync/all_cam{cam[1:]}_to_world.txt\"\n",
    "\n",
    "# Extract poses\n",
    "cam2world = []\n",
    "\n",
    "# Read cam2world matrices\n",
    "for index,line in enumerate(open(pose_file, 'r').readlines()):\n",
    "    if index % interval_size == 0:\n",
    "        value = list(map(float, line.strip().split(\" \")))\n",
    "        cam2world.append(np.array(value[1:]))\n",
    "\n",
    "cam2world = np.array(cam2world)\n",
    "cam2world = cam2world[first_frame:last_frame+1]\n",
    "print(cam2world.shape)\n",
    "# Save only the poses to a .txt file\n",
    "with open(f'{target_folder}/camera_poses.txt', 'w') as file:\n",
    "    for i, row in enumerate(cam2world):\n",
    "        if i % interval_size == 0:\n",
    "            mapped_index = i // interval_size\n",
    "            if mapped_index < len(available_frames): \n",
    "                line = [str(available_frames[mapped_index])] + [str(x) for x in row]\n",
    "                line = ' '.join(line) + '\\n'\n",
    "                file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dict = {}\n",
    "\n",
    "image_dict['url'] = \"\"\n",
    "image_dict['key'] = f\"kitti360_cam{cam}_{first_frame}_{last_frame}\"\n",
    "\n",
    "timestamps = torch.as_tensor(available_frames)\n",
    "image_dict['timestamps'] = timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam2world12 = torch.tensor(cam2world[:, :12])\n",
    "two_zeros = torch.zeros((nb_frames, 2))\n",
    "intrinsics = torch.zeros((nb_frames, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readYAMLFile(fileName):\n",
    "    '''make OpenCV YAML file compatible with python'''\n",
    "    ret = {}\n",
    "    skip_lines=1    # Skip the first line which says \"%YAML:1.0\". Or replace it with \"%YAML 1.0\"\n",
    "    with open(fileName) as fin:\n",
    "        for i in range(skip_lines):\n",
    "            fin.readline()\n",
    "        yamlFileOut = fin.read()\n",
    "        myRe = re.compile(r\":([^ ])\")   # Add space after \":\", if it doesn't exist. Python yaml requirement\n",
    "        yamlFileOut = myRe.sub(r': \\1', yamlFileOut)\n",
    "        ret = yaml.safe_load(yamlFileOut)\n",
    "    return ret\n",
    "\n",
    "intrinsics_file = f'/home/angelika/datasets/kitti_360/calibration/image_{cam}.yaml'\n",
    "intrinsics_dict = readYAMLFile(intrinsics_file)\n",
    "\n",
    "intrinsics[:, 0] = torch.tensor(intrinsics_dict['projection_parameters']['gamma1']).repeat(nb_frames)\n",
    "intrinsics[:, 1] = torch.tensor(intrinsics_dict['projection_parameters']['gamma2']).repeat(nb_frames)\n",
    "intrinsics[:, 2] = torch.tensor(intrinsics_dict['projection_parameters']['u0']).repeat(nb_frames)\n",
    "intrinsics[:, 3] = torch.tensor(intrinsics_dict['projection_parameters']['v0']).repeat(nb_frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Camera parameters\n",
    "poses = torch.cat((intrinsics, two_zeros, cam2world12), dim=1)\n",
    "poses.shape\n",
    "\n",
    "image_dict['cameras'] = poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert images and save them to image_dict\n",
    "\n",
    "flattened_images = []\n",
    "\n",
    "for i, filename in enumerate(filenames):\n",
    "    if i < nb_frames:\n",
    "        available_frames.append(i)\n",
    "        source_path = os.path.join(source_folder, filename)\n",
    "        filename_dest = filename\n",
    "        destination_path = os.path.join(target_folder, filename_dest)\n",
    "        image = Image.open(source_path)\n",
    "        im_resize = image.resize((360, 360))\n",
    "        im_crop = im_resize.crop((80, 220, 720, 580))\n",
    "        im_crop.save(destination_path)\n",
    "        \n",
    "        # Convert image to bytes\n",
    "        byte_stream = BytesIO()\n",
    "        im_crop.save(byte_stream, format='PNG')  # Choose appropriate format, e.g., JPEG, PNG, etc.\n",
    "        image_bytes = byte_stream.getvalue()\n",
    "        byte_stream.close()\n",
    "\n",
    "        # Convert bytes to tensor\n",
    "        frameTensor = torch.tensor(np.frombuffer(image_bytes, dtype=np.uint8))\n",
    "        \n",
    "        flattened_images.append(frameTensor)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test one image\n",
    "# byte_stream = BytesIO()\n",
    "# image.save(byte_stream, format='PNG')  # Choose appropriate format, e.g., JPEG, PNG, etc.\n",
    "# image_bytes = byte_stream.getvalue()\n",
    "# byte_stream.close()\n",
    "\n",
    "# frameTensor = torch.tensor(np.frombuffer(image_bytes, dtype=np.uint8))\n",
    "\n",
    "# Check if the image is loaded correctly\n",
    "# image2 = Image.open(BytesIO(frameTensor.numpy().tobytes()))\n",
    "# image2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the images\n",
    "image_dict['images'] = flattened_images\n",
    "\n",
    "# Save the image_dict to a .torch file\n",
    "data = [image_dict]\n",
    "\n",
    "image_dict_name = \"000000\"\n",
    "torch.save(data, f'{target_folder}/{image_dict_name}.torch')\n",
    "torch.save(data, f'/home/angelika/pixelsplat_fisheye/datasets/kitti360/test/{image_dict_name}.torch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
